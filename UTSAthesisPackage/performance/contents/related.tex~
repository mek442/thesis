\section{Related Works}
\label{sec:related}
In this section, we discuss the previous research efforts related to our work. 
\subsection{Studies on Security Bug Reports}
We are aware of only one previous research work on identifying security bug reports. Gegick et al.~\cite{Gegick10iden} proposed an approach to identifying security bug reports based on term-weighting, and performed an empirical study based on an industry bug repository. Our work in this paper is different from the previous research effort on the following three aspects. First of all, the previous approach requires a manually prepared security-related start term list. By contrast, our approach is fully automatic and generate the list of terms automatically. Second, the previous approach is evaluated on a private bug repository which is not public available, while we construct a data set containing labelled security bug reports from an open bug repository so that the data set can be used in future research in the area. Third, while both the previous approach and our approach require a training set, the previous approach is not evaluated with a small training set which is often the only training set available. Actually, our experimental results show that our technique outperforms the term-ranking only technique, though we are not able to evaluate our approach on the industry data set used in the previous approach.

There have been several other research efforts on security bug reports. Zaman et al.~\cite{Zaman11sec} performed an empirical study on how performance bug reports and security bug reports are handled in open bug repositories. Their key findings include that fixing security bug reports usually requires more experienced developers and more complex code commit, and security bug reports are usually fixed faster than other bug reports. These findings actually support our assumptions that security bug reports needs to be identified earlier and handled separately. Barth et al.~\cite{Barth11open} proposed an approach to attack open source software projects by identify the fixes of recent security bug reports. Since the distribution of new versions of software typically require a long time, it is highly likely that the attack of this fixed security bug can affect a lot of users in real world. The authors suggest that the open bug repositories to hide security bug reports as well as bug fixes until a long time after the fix. These research efforts are not on the identification of security bug reports, and they actually provide motivations to automatic identification of security bug reports.

\subsection{Classification of Bug Reports}
The general problem of classifying bug reports according to certain criteria has been widely researched. The early works in the area mainly try to assign bug reports to different developers. Specifically, Anvik et al.~\cite{CSE06AJ}, Cubranic and Murphy~\cite{SEKE04CD}, and Lucca~\cite{CSM02L} all proposed approaches to automatically assign bug reports. Classification is the major approach used on this topic. Later, Menzies and Marcus also suggested a classification based approach to predict the severity of bug reports~\cite{CSM08TM}. Additionally, Hooimeijer and Weimer suggested a statistics based model to predict the quality of bug reports~\cite{ASE07HP}. Identification of duplicate bug reports is another subarea attracting many researchers. Runeson et al.~\cite{RAN07} and Wang et al.~\cite{WZXAS08} carried out some early works in the area based on the basic similarities of textual information or execution information. Later, Chengnian et al.~\cite{Sun10disc}~\cite{Sun11towards} reported two pieces of research efforts for more precise identification of duplicate bug reports with more sophisticated mining techniques. Specifically, they also used the discriminative weighting of terms, and the weighting is performed automatically by mining the training set~\cite{Sun10disc}. However, they used the weights to calculate a more precise similarity between single bug reports, while in our approach, we use a different weighting formula because we needs the weights to rank terms according whether the terms are representative for a bug category. Furthermore, we combine the term ranking approach with classification and bootstrapping.

\subsection{Automatic Content Tagging}

The identification of security bug reports can be viewed as a specific instance of the automatic content tagging problem~\cite{sheth02manage}, which aims to add meaningful tags to contents on the Internet. The large amount of research efforts to tackle this problem mainly fall into two categories: (1) the approaches based on term weighting, ranking, and retrieval of documents using a list of terms as queries; (2) the approaches based on classification which leverages various standard or adapted machine learning techniques. The first category of approaches mainly focus on more advanced term weighting formulae~\cite{Song08Real}~\cite{Liu09im}, ranking strategies~\cite{Carpineto02improve}~\cite{Wang08exp}, and the adaptation of these techniques in different usage scenarios~\cite{Das09word}. The second category of approaches, mainly focus on the selection of proper features in different usage scenarios~\cite{Hong06auto}~\cite{Lodhi02text}. Recently, there have been some research efforts~\cite{Lan09Super}~\cite{Nallapati04disc} on combining the term ranking and classification approaches. Our work basically leverages the existing scheme of combination, and incorporated the bootstrapping process considering the small training set available for the problem.
